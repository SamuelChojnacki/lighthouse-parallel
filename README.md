# üöÄ Lighthouse Parallel

<div align="center">

**Production-ready API for running Google Lighthouse audits at scale**

[![MIT License](https://img.shields.io/badge/License-MIT-green.svg)](https://choosealicense.com/licenses/mit/)
[![NestJS](https://img.shields.io/badge/NestJS-v11-E0234E?logo=nestjs)](https://nestjs.com/)
[![BullMQ](https://img.shields.io/badge/BullMQ-v5-FF6B6B?logo=redis)](https://bullmq.io/)
[![Lighthouse](https://img.shields.io/badge/Lighthouse-v12-F44B21?logo=lighthouse)](https://github.com/GoogleChrome/lighthouse)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.7-3178C6?logo=typescript)](https://www.typescriptlang.org/)
[![React](https://img.shields.io/badge/React-19-61DAFB?logo=react)](https://react.dev/)

[Features](#-features) ‚Ä¢ [Quick Start](#-quick-start) ‚Ä¢ [API Docs](#-api-documentation) ‚Ä¢ [Architecture](#-architecture) ‚Ä¢ [Contributing](#-contributing)

</div>

---

## üìñ Overview

Lighthouse Parallel is a **high-performance API** that enables running Google Lighthouse audits **concurrently at massive scale**. Built with NestJS, BullMQ, and modern DevOps practices, it's designed for:

- üè¢ **Enterprises** monitoring hundreds of web properties
- üìä **Performance teams** running continuous audits in CI/CD
- üîç **SEO agencies** analyzing client websites at scale
- üõ†Ô∏è **Developers** integrating performance testing into workflows

### Why Lighthouse Parallel?

| Problem | Solution |
|---------|----------|
| Running audits sequentially is **slow** ‚è±Ô∏è | **Parallel execution** with configurable workers |
| Chrome instances are **resource-heavy** üíæ | **Isolated child processes** with smart lifecycle management |
| Managing job queues is **complex** ü§Ø | **BullMQ integration** with retry logic & monitoring |
| No built-in **reporting dashboard** üìä | **Modern React dashboard** with real-time updates |
| Difficult to **integrate webhooks** üîî | **Built-in webhook support** for CI/CD pipelines |

---

## ‚ú® Features

### üéØ Core Capabilities

- **‚ö° Massive Parallelism**: Run 8-32 concurrent audits (configurable based on server resources)
- **üåç Internationalization**: Generate reports in 20+ languages (`en`, `fr`, `de`, `es`, `ja`, etc.)
- **üì¶ Batch Processing**: Audit hundreds of URLs with a single API call
- **üîÑ Smart Retries**: Automatic retry with exponential backoff on failures
- **ü™ù Webhooks**: Real-time notifications when audits complete
- **üìä Prometheus Metrics**: Production-grade monitoring and observability
- **üé® Modern Dashboard**: React-based UI for managing audits and viewing results
- **üîí Security**: API key authentication, JWT tokens, Helmet protection
- **üê≥ Docker Ready**: Production-optimized multi-stage builds
- **üìà Auto-scaling**: Handles traffic spikes with BullMQ's smart concurrency

### üõ†Ô∏è Technical Highlights

- **Zero Race Conditions**: Parent-controlled child process lifecycle (no arbitrary timeouts)
- **Resource Efficient**: Automatic cleanup of completed jobs and reports
- **Health Checks**: `/health` endpoints for Kubernetes/Docker orchestration
- **Structured Logging**: Winston with daily rotation for production debugging
- **Type Safety**: Full TypeScript across backend and frontend
- **Developer Experience**: Hot reload, comprehensive error handling, Swagger docs

---

## üöÄ Quick Start

### Prerequisites

- **Node.js** 20+ and npm 9+
- **Docker** & Docker Compose (recommended)
- **Redis** 6+ (included in docker-compose)

### üê≥ Docker Setup (Recommended)

```bash
# Clone the repository
git clone https://github.com/yourusername/lighthouse-parallel.git
cd lighthouse-parallel

# Generate secure credentials
node -e "console.log(require('crypto').randomBytes(32).toString('base64'))" > .api-key
node -e "console.log(require('crypto').randomBytes(64).toString('base64'))" > .jwt-secret

# Create .env file
cat > .env << EOF
PORT=3002
REDIS_HOST=redis
REDIS_PORT=6379
API_KEY=$(cat .api-key)
JWT_SECRET=$(cat .jwt-secret)
WORKER_CONCURRENCY=8
NODE_ENV=production
EOF

# Start all services
docker-compose up --build

# API available at http://localhost:3002
# Dashboard at http://localhost:3002/ (login with configured password)
```

### üíª Local Development

```bash
# Install dependencies
npm install
cd frontend && npm install && cd ..

# Start Redis
docker-compose up redis -d

# Configure environment
cp .env.example .env
# Edit .env with your credentials

# Run in development mode
npm run start:dev

# Build for production
npm run build
npm run start:prod
```

---

## üìö API Documentation

### Authentication

All API requests require authentication via API key:

```bash
curl -H "X-API-Key: YOUR_API_KEY" http://localhost:3002/lighthouse/stats
```

### Endpoints

#### üîç Single Audit

```bash
POST /lighthouse/audit
```

```json
{
  "url": "https://example.com",
  "categories": ["performance", "accessibility", "seo"],
  "locale": "fr",
  "webhookUrl": "https://your-app.com/webhook",
  "webhookToken": "secret"
}
```

**Response:**
```json
{
  "jobId": "550e8400-e29b-41d4-a716-446655440000",
  "url": "https://example.com",
  "status": "queued",
  "reportUrl": "/reports/550e8400-e29b-41d4-a716-446655440000.json"
}
```

#### üì¶ Batch Audits

```bash
POST /lighthouse/batch
```

```json
{
  "urls": [
    "https://example.com",
    "https://google.com",
    "https://github.com"
  ],
  "categories": ["performance"],
  "locale": "de",
  "webhookUrl": "https://your-app.com/batch-webhook"
}
```

**Response:**
```json
{
  "batchId": "batch-550e8400-e29b-41d4-a716-446655440000",
  "total": 3,
  "jobIds": ["job1", "job2", "job3"],
  "status": "processing"
}
```

#### üìä Check Status

```bash
GET /lighthouse/job/:jobId
GET /lighthouse/batch/:batchId
GET /lighthouse/stats
```

#### üóëÔ∏è Cleanup (Admin)

```bash
POST /lighthouse/cleanup
```

### Webhooks

When a job completes, a POST request is sent to your `webhookUrl`:

```json
{
  "jobId": "550e8400-e29b-41d4-a716-446655440000",
  "url": "https://example.com",
  "status": "completed",
  "performance": 95,
  "accessibility": 100,
  "reportUrl": "https://your-api.com/reports/550e8400.json"
}
```

---

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   React SPA     ‚îÇ  ‚Üê Modern Dashboard (Vite + React 19 + Tailwind)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ HTTP/REST
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           NestJS API (Port 3002)                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Controllers (Auth, Audit, Admin, Logs)  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                   ‚îÇ                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ     Lighthouse Service (Job Manager)     ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ   BullMQ Queue      ‚îÇ ‚Üê Redis-backed job queue
         ‚îÇ  (8-32 concurrent)  ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇ   Lighthouse Processor    ‚îÇ
      ‚îÇ  (Worker with concurrency ‚îÇ
      ‚îÇ   controlled by parent)   ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ  Child Process Pool    ‚îÇ
        ‚îÇ  ‚îå‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îê  ‚îÇ
        ‚îÇ  ‚îÇC1‚îÇ ‚îÇC2‚îÇ ‚îÇ..‚îÇ ‚îÇCN‚îÇ  ‚îÇ ‚Üê Isolated Chrome instances
        ‚îÇ  ‚îî‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îò  ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ    Lighthouse Core     ‚îÇ ‚Üê Google's audit engine
        ‚îÇ   (Performance, SEO,   ‚îÇ
        ‚îÇ   Accessibility, etc.) ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Key Design Decisions

1. **Parent-Controlled Lifecycle**: No arbitrary timeouts - parent process fully controls child termination with SIGKILL
2. **Process Isolation**: Each audit runs in a forked child process with dedicated Chrome instance
3. **Smart Concurrency**: Worker count configurable based on server CPU/RAM (1-2x vCPU cores)
4. **Graceful Shutdown**: BullMQ handles in-flight jobs during deployment
5. **Stateless Workers**: Horizontal scaling ready (add more workers/servers)

---

## üìä Performance

### Benchmarks

| Scenario | Sequential | Parallel (8 workers) | Speedup |
|----------|------------|----------------------|---------|
| 10 audits | ~450s | ~60s | **7.5x** |
| 50 audits | ~2250s | ~300s | **7.5x** |
| 100 audits | ~4500s | ~600s | **7.5x** |

**Test environment**: 16 vCPU, 64GB RAM, Hetzner Cloud

### Resource Usage

- **Memory**: ~400MB per Chrome instance
- **CPU**: ~0.5-1 vCPU per active audit
- **Recommended**: 16 workers on 16 vCPU machine

### Scaling Recommendations

| Server Specs | Recommended Workers |
|--------------|---------------------|
| 4 vCPU, 8GB RAM | 4-6 workers |
| 8 vCPU, 16GB RAM | 8-12 workers |
| 16 vCPU, 64GB RAM | 16-24 workers ‚≠ê |
| 32 vCPU, 128GB RAM | 32-48 workers |

---

## üõ†Ô∏è Configuration

### Environment Variables

```env
# Server
PORT=3002
NODE_ENV=production

# Redis
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0

# Security
API_KEY=your-secure-api-key
JWT_SECRET=your-jwt-secret
DASHBOARD_PASSWORD_HASH=bcrypt-hash

# Performance
WORKER_CONCURRENCY=8  # Adjust based on server resources

# CORS
CORS_ORIGINS=http://localhost:5173,https://your-domain.com
```

### Lighthouse Options

Customize audit settings in `src/lighthouse/workers/lighthouse-runner.js`:

```javascript
const lighthouseOptions = {
  logLevel: 'error',
  output: 'json',
  onlyCategories: ['performance', 'accessibility', 'seo', 'best-practices'],
  locale: 'en',
  formFactor: 'mobile',
  throttling: {
    rttMs: 150,
    throughputKbps: 1638.4,
    cpuSlowdownMultiplier: 4
  }
};
```

---

## üê≥ Production Deployment

### Docker Compose

```yaml
version: '3.8'

services:
  redis:
    image: redis:7-alpine
    volumes:
      - redis-data:/data

  api:
    build: .
    ports:
      - "3002:3002"
    environment:
      REDIS_HOST: redis
      WORKER_CONCURRENCY: 16
    depends_on:
      - redis
    deploy:
      resources:
        limits:
          cpus: '8'
          memory: 16G
```

### Kubernetes

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: lighthouse-api
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: api
        image: lighthouse-parallel:latest
        resources:
          requests:
            cpu: "4"
            memory: "8Gi"
          limits:
            cpu: "8"
            memory: "16Gi"
        env:
        - name: WORKER_CONCURRENCY
          value: "8"
```

---

## üß™ Testing

```bash
# Unit tests
npm test

# E2E tests
npm run test:e2e

# Coverage
npm run test:cov
```

---

## ü§ù Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for details.

### Development Setup

1. Fork the repo
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Make your changes
4. Run tests: `npm test`
5. Commit: `git commit -m 'Add amazing feature'`
6. Push: `git push origin feature/amazing-feature`
7. Open a Pull Request

### Contribution Ideas

- üåü Add support for custom Lighthouse configs
- üìä Enhance dashboard with charts and analytics
- üîå Add integrations (Slack, Discord, Teams)
- üß™ Improve test coverage
- üìù Translate documentation to other languages
- üöÄ Performance optimizations
- üêõ Bug fixes and improvements

---

## üó∫Ô∏è Roadmap

- [x] Parallel audit execution
- [x] Batch processing
- [x] Webhook notifications
- [x] React dashboard
- [x] Multi-language reports
- [x] Prometheus metrics
- [ ] GraphQL API
- [ ] WebSocket real-time updates
- [ ] Historical trend analysis
- [ ] Custom Lighthouse plugins
- [ ] Slack/Discord integrations
- [ ] Scheduled recurring audits
- [ ] PDF report generation

---

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## üôè Acknowledgments

- [Google Lighthouse](https://github.com/GoogleChrome/lighthouse) - The audit engine
- [NestJS](https://nestjs.com/) - Progressive Node.js framework
- [BullMQ](https://bullmq.io/) - Premium queue package for handling distributed jobs
- [Chrome Launcher](https://github.com/GoogleChrome/chrome-launcher) - Chrome instance management

---

## üìû Support

- üìß Email: support@lighthouse-parallel.dev
- üêõ Issues: [GitHub Issues](https://github.com/yourusername/lighthouse-parallel/issues)
- üí¨ Discussions: [GitHub Discussions](https://github.com/yourusername/lighthouse-parallel/discussions)
- üìñ Documentation: [Wiki](https://github.com/yourusername/lighthouse-parallel/wiki)

---

<div align="center">

**‚≠ê Star this repo if you find it useful!**

Made with ‚ù§Ô∏è by Saba√Ø team

</div>
